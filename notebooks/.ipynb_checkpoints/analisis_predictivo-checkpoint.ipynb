{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87df6e93",
   "metadata": {},
   "source": [
    "# Análisis Predictivo para TFM de Business Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd0eed",
   "metadata": {},
   "source": [
    "Este Jupyter Notebook documenta el proceso de análisis de datos y entrenamiento de modelos de Machine Learning para la aplicación de Business Intelligence. Se abordarán dos casos de uso principales: **predicción de ventas** y **predicción de averías>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144d227",
   "metadata": {},
   "source": [
    "## 1. Carga y Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix\n",
    "    import joblib # Para guardar los modelos\n",
    "    \n",
    "    \n",
    "    # Carga de datos de ventas\n",
    "    try:\n",
    "        df_sales = pd.read_csv('../data/sales_data_example.csv')\n",
    "        print(\"Datos de ventas cargados correctamente.\")\n",
    "        print(df_sales.head())\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: sales_data_example.csv no encontrado. Asegúrate de que el archivo está en la carpeta 'data'.\")\n",
    "        df_sales = pd.DataFrame() # Crear un DataFrame vacío para evitar errores posteriores\n",
    "    \n",
    "    # Carga de datos de mantenimiento\n",
    "    try:\n",
    "        df_maintenance = pd.read_csv('../data/maintenance_data_example.csv')\n",
    "        print(\"\n",
    "Datos de mantenimiento cargados correctamente.\")\n",
    "        print(df_maintenance.head())\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: maintenance_data_example.csv no encontrado. Asegúrate de que el archivo está en la carpeta 'data'.\")\n",
    "        df_maintenance = pd.DataFrame() # Crear un DataFrame vacío para evitar errores posteriores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731b59d",
   "metadata": {},
   "source": [
    "### Limpieza y Preprocesamiento de Datos de Ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29657a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_sales.empty:\n",
    "        # Convertir 'Date' a formato datetime\n",
    "        df_sales['Date'] = pd.to_datetime(df_sales['Date'])\n",
    "    \n",
    "        # Crear características adicionales a partir de la fecha\n",
    "        df_sales['Month'] = df_sales['Date'].dt.month\n",
    "        df_sales['DayOfWeek'] = df_sales['Date'].dt.dayofweek\n",
    "    \n",
    "        # Codificación One-Hot para variables categóricas\n",
    "        df_sales = pd.get_dummies(df_sales, columns=['Region', 'Promotion', 'Holiday'], drop_first=True)\n",
    "    \n",
    "        # Eliminar columnas no necesarias para el modelo\n",
    "        df_sales_processed = df_sales.drop(['Date', 'Product_ID'], axis=1)\n",
    "    \n",
    "        print(\"\n",
    "Datos de ventas preprocesados:\")\n",
    "        print(df_sales_processed.head())\n",
    "        print(df_sales_processed.info())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da0149",
   "metadata": {},
   "source": [
    "### Limpieza y Preprocesamiento de Datos de Mantenimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_maintenance.empty:\n",
    "        # Eliminar columnas no necesarias para el modelo (ej. Machine_ID si no se usa como característica)\n",
    "        df_maintenance_processed = df_maintenance.drop(['Machine_ID'], axis=1)\n",
    "    \n",
    "        print(\"\n",
    "Datos de mantenimiento preprocesados:\")\n",
    "        print(df_maintenance_processed.head())\n",
    "        print(df_maintenance_processed.info())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f49609",
   "metadata": {},
   "source": [
    "## 2. Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce6a0c",
   "metadata": {},
   "source": [
    "### Modelo de Predicción de Ventas (Regresión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58812cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_sales.empty:\n",
    "        X_sales = df_sales_processed.drop('Sales', axis=1)\n",
    "        y_sales = df_sales_processed['Sales']\n",
    "    \n",
    "        X_train_sales, X_test_sales, y_train_sales, y_test_sales = train_test_split(X_sales, y_sales, test_size=0.2, random_state=42)\n",
    "    \n",
    "        model_sales = LinearRegression()\n",
    "        model_sales.fit(X_train_sales, y_train_sales)\n",
    "    \n",
    "        y_pred_sales = model_sales.predict(X_test_sales)\n",
    "    \n",
    "        mse_sales = mean_squared_error(y_test_sales, y_pred_sales)\n",
    "        r2_sales = r2_score(y_test_sales, y_pred_sales)\n",
    "    \n",
    "        print(f\"\n",
    "### Evaluación del Modelo de Ventas ###\")\n",
    "        print(f\"Error Cuadrático Medio (MSE): {mse_sales:.2f}\")\n",
    "        print(f\"Coeficiente de Determinación (R2): {r2_sales:.2f}\")\n",
    "    \n",
    "        # Guardar el modelo de ventas\n",
    "        joblib.dump(model_sales, '../backend/models/model_sales.pkl')\n",
    "        print(\"Modelo de ventas guardado como ../backend/models/model_sales.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28372d",
   "metadata": {},
   "source": [
    "### Modelo de Predicción de Averías (Clasificación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a72f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_maintenance.empty:\n",
    "        X_maintenance = df_maintenance_processed.drop('Failure', axis=1)\n",
    "        y_maintenance = df_maintenance_processed['Failure']\n",
    "    \n",
    "        X_train_maintenance, X_test_maintenance, y_train_maintenance, y_test_maintenance = train_test_split(X_maintenance, y_maintenance, test_size=0.2, random_state=42)\n",
    "    \n",
    "        model_maintenance = LogisticRegression(solver='liblinear', random_state=42) # Usamos LogisticRegression para clasificación binaria\n",
    "        model_maintenance.fit(X_train_maintenance, y_train_maintenance)\n",
    "    \n",
    "        y_pred_maintenance = model_maintenance.predict(X_test_maintenance)\n",
    "    \n",
    "        accuracy_maintenance = accuracy_score(y_test_maintenance, y_pred_maintenance)\n",
    "        report_maintenance = classification_report(y_test_maintenance, y_pred_maintenance)\n",
    "        cm_maintenance = confusion_matrix(y_test_maintenance, y_pred_maintenance)\n",
    "    \n",
    "        print(f\"\n",
    "### Evaluación del Modelo de Averías ###\")\n",
    "        print(f\"Accuracy: {accuracy_maintenance:.2f}\")\n",
    "        print(\"Reporte de Clasificación:\n",
    "\", report_maintenance)\n",
    "        print(\"Matriz de Confusión:\n",
    "\", cm_maintenance)\n",
    "    \n",
    "        # Guardar el modelo de mantenimiento\n",
    "        joblib.dump(model_maintenance, '../backend/models/model_maintenance.pkl')\n",
    "        print(\"Modelo de averías guardado como ../backend/models/model_maintenance.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40dfe7e",
   "metadata": {},
   "source": [
    "## 3. Explicación de los Algoritmos Usados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bcc32f",
   "metadata": {},
   "source": [
    "### Regresión Lineal (para Predicción de Ventas)\n",
    "    La Regresión Lineal es un algoritmo de aprendizaje supervisado que modela la relación entre una variable dependiente (la que queremos predecir, en este caso 'Sales') y una o más variables independientes (las características de entrada). Asume una relación lineal entre las variables. El objetivo es encontrar la línea (o hiperplano en múltiples dimensiones) que mejor se ajusta a los datos, minimizando la suma de los errores cuadrados entre los valores predichos y los valores reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad058c1",
   "metadata": {},
   "source": [
    "### Regresión Logística (para Predicción de Averías)\n",
    "    A pesar de su nombre, la Regresión Logística es un algoritmo de clasificación, no de regresión. Se utiliza para predecir la probabilidad de una variable dependiente binaria (0 o 1, en este caso 'Failure'). Utiliza una función logística (o sigmoide) para transformar la salida lineal en una probabilidad entre 0 y 1. Si la probabilidad supera un umbral (comúnmente 0.5), se clasifica como 1; de lo contrario, como 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d021ab2",
   "metadata": {},
   "source": [
    "## 4. Predicción sobre Nuevos Datos (Ejemplos Funcionales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2247d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_sales.empty:\n",
    "        # Cargar el modelo de ventas guardado\n",
    "        loaded_model_sales = joblib.load('../backend/models/model_sales.pkl')\n",
    "    \n",
    "        # Ejemplo de nuevos datos para predicción de ventas\n",
    "        # Asegúrate de que las columnas y el orden coincidan con el entrenamiento\n",
    "        # Las columnas categóricas deben estar codificadas de la misma manera\n",
    "        # Para este ejemplo, asumimos que las columnas dummy son 'Region_West', 'Region_North', 'Region_South', 'Promotion_Yes', 'Holiday_Yes'\n",
    "        # y que 'Month', 'DayOfWeek', 'Temperature', 'Customers', 'Marketing_Spend' son numéricas.\n",
    "    \n",
    "        # Crear un DataFrame con las columnas esperadas por el modelo\n",
    "        # Es crucial que el orden y el nombre de las columnas sean EXACTOS a como se entrenó el modelo.\n",
    "        # Para simplificar, usaremos las columnas del primer registro de df_sales_processed (excluyendo 'Sales')\n",
    "        # y modificaremos algunos valores para ver la predicción.\n",
    "    \n",
    "        # Obtener las columnas que el modelo espera (todas excepto 'Sales')\n",
    "        model_sales_features = df_sales_processed.drop('Sales', axis=1).columns.tolist()\n",
    "    \n",
    "        # Crear un nuevo DataFrame con un solo registro de ejemplo\n",
    "        # Asegúrate de que los valores de las columnas dummy sean 0 o 1\n",
    "        new_sales_data = pd.DataFrame([[1, 1, 25, 60, 22, 0, 0, 0, 0, 0]], \n",
    "                                      columns=['Month', 'DayOfWeek', 'Temperature', 'Customers', 'Marketing_Spend', \n",
    "                                               'Region_East', 'Region_North', 'Region_South', 'Promotion_Yes', 'Holiday_Yes'])\n",
    "        \n",
    "        # Asegurarse de que las columnas coincidan exactamente con las del entrenamiento\n",
    "        # Esto es una simplificación. En un caso real, se necesitaría un pipeline de preprocesamiento.\n",
    "        # Para este ejemplo, se asume que el orden de las columnas es el mismo.\n",
    "        # Si el modelo se entrenó con 'Region_East', 'Region_North', 'Region_South', 'Promotion_Yes', 'Holiday_Yes'\n",
    "        # y el ejemplo tiene 'Region_West', 'Promotion_No', 'Holiday_No', entonces los valores serían:\n",
    "        # Region_East=0, Region_North=0, Region_South=0, Promotion_Yes=0, Holiday_Yes=0\n",
    "    \n",
    "        # Ejemplo de datos para predicción (ajustado para que coincida con las columnas dummy generadas)\n",
    "        # Asumiendo que las columnas dummy son 'Region_East', 'Region_North', 'Region_South', 'Promotion_Yes', 'Holiday_Yes'\n",
    "        # y que el ejemplo original tenía 'Region'='West', 'Promotion'='No', 'Holiday'='No'\n",
    "        # Esto significa que 'Region_East', 'Region_North', 'Region_South', 'Promotion_Yes', 'Holiday_Yes' serían 0\n",
    "        # Si queremos predecir para un caso similar:\n",
    "        # entonces 'Region_East'=1, 'Promotion_Yes'=1, 'Holiday_Yes'=0\n",
    "    \n",
    "        # Para el ejemplo de df_sales.head() que tiene 'Region'='East', 'Promotion'='No', 'Holiday'='No'\n",
    "        # Las columnas dummy generadas serían: Region_East=1, Promotion_Yes=0, Holiday_Yes=0\n",
    "        # Si queremos predecir para un caso similar:\n",
    "        new_sales_data_example = pd.DataFrame({\n",
    "            'Temperature': [15],\n",
    "            'Customers': [70],\n",
    "            'Marketing_Spend': [30],\n",
    "            'Month': [1],\n",
    "            'DayOfWeek': [0],\n",
    "            'Region_East': [1], # Ejemplo: East\n",
    "            'Region_North': [0],\n",
    "            'Region_South': [0],\n",
    "            'Promotion_Yes': [1], # Ejemplo: Con promoción\n",
    "            'Holiday_Yes': [0]  # Ejemplo: No es festivo\n",
    "        })\n",
    "    \n",
    "        # Asegurarse de que el orden de las columnas sea el mismo que el de entrenamiento\n",
    "        new_sales_data_example = new_sales_data_example[X_sales.columns]\n",
    "    \n",
    "        predicted_sales = loaded_model_sales.predict(new_sales_data_example)\n",
    "        print(f\"\n",
    "Predicción de ventas para nuevos datos: {predicted_sales[0]:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85844c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_maintenance.empty:\n",
    "        # Cargar el modelo de mantenimiento guardado\n",
    "        loaded_model_maintenance = joblib.load('../backend/models/model_maintenance.pkl')\n",
    "    \n",
    "        # Ejemplo de nuevos datos para predicción de averías\n",
    "        # Asegúrate de que las columnas y el orden coincidan con el entrenamiento\n",
    "        new_maintenance_data = pd.DataFrame([[25.0, 80.0, 12.0, 30.0, 10.0, 5.0]], \n",
    "                                            columns=['Sensor1', 'Sensor2', 'Sensor3', 'Temperature', 'Pressure', 'Vibration'])\n",
    "    \n",
    "        predicted_failure = loaded_model_maintenance.predict(new_maintenance_data)\n",
    "        predicted_failure_proba = loaded_model_maintenance.predict_proba(new_maintenance_data)[:, 1]\n",
    "    \n",
    "        print(f\"\n",
    "Predicción de avería para nuevos datos (0=No Avería, 1=Avería): {predicted_failure[0]}\")\n",
    "        print(f\"Probabilidad de avería: {predicted_failure_proba[0]:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b8fc5",
   "metadata": {},
   "source": [
    "## 5. Gráficos y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_sales.empty:\n",
    "        # Gráfico de dispersión de Ventas vs. Marketing_Spend\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x='Marketing_Spend', y='Sales', data=df_sales)\n",
    "        plt.title('Ventas vs. Gasto en Marketing')\n",
    "        plt.xlabel('Gasto en Marketing')\n",
    "        plt.ylabel('Ventas')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "        # Histograma de Ventas\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(df_sales['Sales'], kde=True)\n",
    "        plt.title('Distribución de Ventas')\n",
    "        plt.xlabel('Ventas')\n",
    "        plt.ylabel('Frecuencia')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b061ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_maintenance.empty:\n",
    "        # Gráfico de barras de la distribución de averías\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.countplot(x='Failure', data=df_maintenance)\n",
    "        plt.title('Distribución de Averías (0=No Avería, 1=Avería)')\n",
    "        plt.xlabel('Avería')\n",
    "        plt.ylabel('Conteo')\n",
    "        plt.xticks([0, 1], ['No Avería', 'Avería'])\n",
    "        plt.grid(axis='y')\n",
    "        plt.show()\n",
    "    \n",
    "        # Matriz de correlación para datos de mantenimiento\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(df_maintenance_processed.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.title('Matriz de Correlación de Datos de Mantenimiento')\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab4cbd",
   "metadata": {},
   "source": [
    "## Conclusiones Generales\n",
    "    Este notebook ha demostrado el proceso de carga, preprocesamiento, entrenamiento y evaluación de modelos de Machine Learning para la predicción de ventas y averías. Los modelos entrenados (`LinearRegression` y `LogisticRegression`) son ejemplos básicos que pueden ser mejorados con más datos, ingeniería de características avanzada y modelos más complejos. Los modelos guardados (`.pkl`) serán utilizados por la API de FastAPI para realizar predicciones en tiempo real."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
